{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook contains the code for training the CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-11 16:30:27,371 INFO Device is cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "import time\n",
    "import warnings\n",
    "import logging as logger\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from dotmap import DotMap\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from convcrf.convcrf import GaussCRF, default_conf\n",
    "from utils.synthetic import augment_label\n",
    "from utils.metrics import Metrics, Averages\n",
    "from demo import do_crf_inference\n",
    "\n",
    "logger.basicConfig(format='%(asctime)s %(levelname)s %(message)s',\n",
    "                    level=logger.INFO,\n",
    "                    stream=sys.stdout)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "logger.info('Device is {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from utils.pascal_loader import PascalDatasetLoader\n",
    "\n",
    "path = '/home/jupyter/projects/ConvCRF/datasets/pascal/VOCdevkit/VOC2012'\n",
    "traincrf_dataset = PascalDatasetLoader(path, split='traincrf')\n",
    "val_dataset = PascalDatasetLoader(path, split='val')\n",
    "\n",
    "num_classes = traincrf_dataset.num_classes\n",
    "\n",
    "traincrf_loader = DataLoader(traincrf_dataset, num_workers=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussCRF(\n",
       "  (CRF): ConvCRF()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = default_conf\n",
    "model = GaussCRF(conf=config, shape=(500, 500), nclasses=num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion= nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "args = DotMap()\n",
    "args.pyinn = False\n",
    "args.nospeed = False\n",
    "args.output = None\n",
    "\n",
    "running_metrics = Metrics(num_classes)\n",
    "train_loss_avg = Averages()\n",
    "val_loss_avg = Averages()\n",
    "time_avg = Averages()\n",
    "\n",
    "best_iou = -100.0\n",
    "\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0] Average loss: 1.0660 Average Time: 1.7075 \n",
      "[1, 20] Average loss: 1.1590 Average Time: 1.5371 \n",
      "[1, 40] Average loss: 1.0457 Average Time: 1.5706 \n",
      "[1, 60] Average loss: 1.2082 Average Time: 1.5735 \n",
      "[1, 80] Average loss: 0.9830 Average Time: 1.5658 \n",
      "[1, 100] Average loss: 1.1298 Average Time: 1.5721 \n",
      "[1, 120] Average loss: 1.2845 Average Time: 1.5681 \n",
      "[1, 140] Average loss: 1.1175 Average Time: 1.5803 \n",
      "[1, 160] Average loss: 0.8125 Average Time: 1.5774 \n",
      "[1, 180] Average loss: 1.0220 Average Time: 1.5830 \n",
      "2018-11-11 16:36:42,817 INFO Doing validation at Epoch: 1\n",
      "2018-11-11 17:00:34,100 INFO Epoch 1 Loss: 1.1842\n",
      "\n",
      "Epoch: 1 Validation Suammry\n",
      "Mean IoU : \t 0.8853168076810695\n",
      "FreqW Acc : \t 0.9580514563346489\n",
      "Overall Acc: \t 0.9781673512767426\n",
      "Mean Acc : \t 0.9374194802572818\n",
      "2018-11-11 17:00:34,107 INFO Found new best_iou: 0.8853168076810695\n",
      "2018-11-11 17:00:34,108 INFO /home/jupyter/projects/ConvCRF/datasets/best_model.pkl\n",
      "[2, 0] Average loss: 1.4249 Average Time: 1.5881 \n",
      "[2, 20] Average loss: 1.1697 Average Time: 1.5308 \n",
      "[2, 40] Average loss: 1.0562 Average Time: 1.5228 \n",
      "[2, 60] Average loss: 1.1716 Average Time: 1.5278 \n",
      "[2, 80] Average loss: 1.1006 Average Time: 1.5386 \n",
      "[2, 100] Average loss: 0.9522 Average Time: 1.5296 \n",
      "[2, 120] Average loss: 1.1145 Average Time: 1.5220 \n",
      "[2, 140] Average loss: 0.7697 Average Time: 1.5265 \n",
      "[2, 160] Average loss: 0.8376 Average Time: 1.5231 \n",
      "[2, 180] Average loss: 1.2019 Average Time: 1.5252 \n",
      "2018-11-11 17:05:40,571 INFO Doing validation at Epoch: 2\n",
      "2018-11-11 17:29:28,144 INFO Epoch 2 Loss: 1.1603\n",
      "\n",
      "Epoch: 2 Validation Suammry\n",
      "Mean IoU : \t 0.8917226986613837\n",
      "FreqW Acc : \t 0.9605339518995087\n",
      "Overall Acc: \t 0.9796048999309869\n",
      "Mean Acc : \t 0.9304138301710625\n",
      "2018-11-11 17:29:28,160 INFO Found new best_iou: 0.8917226986613837\n",
      "2018-11-11 17:29:28,161 INFO /home/jupyter/projects/ConvCRF/datasets/best_model.pkl\n",
      "[3, 0] Average loss: 0.9298 Average Time: 1.5280 \n",
      "[3, 20] Average loss: 1.0914 Average Time: 1.5252 \n",
      "[3, 40] Average loss: 0.9275 Average Time: 1.5277 \n",
      "[3, 60] Average loss: 0.9106 Average Time: 1.5376 \n",
      "[3, 80] Average loss: 1.1840 Average Time: 1.5365 \n",
      "[3, 100] Average loss: 0.7898 Average Time: 1.5284 \n",
      "[3, 120] Average loss: 0.9284 Average Time: 1.5347 \n",
      "[3, 140] Average loss: 0.8349 Average Time: 1.5358 \n",
      "[3, 160] Average loss: 1.0612 Average Time: 1.5408 \n",
      "[3, 180] Average loss: 1.1407 Average Time: 1.5230 \n",
      "2018-11-11 17:34:35,589 INFO Doing validation at Epoch: 3\n",
      "2018-11-11 17:58:24,228 INFO Epoch 3 Loss: 1.1495\n",
      "\n",
      "Epoch: 3 Validation Suammry\n",
      "Mean IoU : \t 0.8925950632217654\n",
      "FreqW Acc : \t 0.9608376113255274\n",
      "Overall Acc: \t 0.9797909813664596\n",
      "Mean Acc : \t 0.9281921469081515\n",
      "2018-11-11 17:58:24,234 INFO Found new best_iou: 0.8925950632217654\n",
      "2018-11-11 17:58:24,236 INFO /home/jupyter/projects/ConvCRF/datasets/best_model.pkl\n",
      "[4, 0] Average loss: 1.0350 Average Time: 1.5361 \n",
      "[4, 20] Average loss: 0.7924 Average Time: 1.5227 \n",
      "[4, 40] Average loss: 0.8801 Average Time: 1.5317 \n",
      "[4, 60] Average loss: 0.8450 Average Time: 1.5302 \n",
      "[4, 80] Average loss: 1.4440 Average Time: 1.5321 \n",
      "[4, 100] Average loss: 0.9846 Average Time: 1.5279 \n",
      "[4, 120] Average loss: 0.8810 Average Time: 1.5289 \n",
      "[4, 140] Average loss: 1.2050 Average Time: 1.5312 \n",
      "[4, 160] Average loss: 0.8992 Average Time: 1.5306 \n",
      "[4, 180] Average loss: 1.1656 Average Time: 1.5280 \n",
      "2018-11-11 18:03:31,127 INFO Doing validation at Epoch: 4\n",
      "2018-11-11 18:27:12,723 INFO Epoch 4 Loss: 1.1422\n",
      "\n",
      "Epoch: 4 Validation Suammry\n",
      "Mean IoU : \t 0.8926313192712678\n",
      "FreqW Acc : \t 0.9609120894086215\n",
      "Overall Acc: \t 0.9798333526570049\n",
      "Mean Acc : \t 0.927377005558111\n",
      "2018-11-11 18:27:12,748 INFO Found new best_iou: 0.8926313192712678\n",
      "2018-11-11 18:27:12,751 INFO /home/jupyter/projects/ConvCRF/datasets/best_model.pkl\n",
      "[5, 0] Average loss: 0.7047 Average Time: 1.5314 \n",
      "[5, 20] Average loss: 0.7476 Average Time: 1.5272 \n",
      "[5, 40] Average loss: 1.1541 Average Time: 1.5265 \n",
      "[5, 60] Average loss: 0.9533 Average Time: 1.5245 \n",
      "[5, 80] Average loss: 1.0218 Average Time: 1.5285 \n",
      "[5, 100] Average loss: 1.1226 Average Time: 1.5221 \n",
      "[5, 120] Average loss: 0.8257 Average Time: 1.5329 \n",
      "[5, 140] Average loss: 0.9952 Average Time: 1.5256 \n",
      "[5, 160] Average loss: 0.8232 Average Time: 1.5303 \n",
      "[5, 180] Average loss: 1.2474 Average Time: 1.5327 \n",
      "2018-11-11 18:32:19,258 INFO Doing validation at Epoch: 5\n",
      "2018-11-11 18:56:02,767 INFO Epoch 5 Loss: 1.1359\n",
      "\n",
      "Epoch: 5 Validation Suammry\n",
      "Mean IoU : \t 0.8926943088943408\n",
      "FreqW Acc : \t 0.960884199585934\n",
      "Overall Acc: \t 0.9798154782608696\n",
      "Mean Acc : \t 0.9278655476283839\n",
      "2018-11-11 18:56:02,774 INFO Found new best_iou: 0.8926943088943408\n",
      "2018-11-11 18:56:02,775 INFO /home/jupyter/projects/ConvCRF/datasets/best_model.pkl\n",
      "[6, 0] Average loss: 0.8042 Average Time: 1.5362 \n",
      "[6, 20] Average loss: 1.0698 Average Time: 1.5309 \n",
      "[6, 40] Average loss: 0.9232 Average Time: 1.5366 \n",
      "[6, 60] Average loss: 0.6708 Average Time: 1.5411 \n",
      "[6, 80] Average loss: 0.9850 Average Time: 1.5396 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-84:\n",
      "Process Process-88:\n",
      "Process Process-85:\n",
      "Process Process-86:\n",
      "Process Process-87:\n",
      "Process Process-82:\n",
      "Process Process-83:\n",
      "Process Process-81:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/usr/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-10d283d1ca1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs): \n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(traincrf_loader):\n",
    "        \n",
    "        start_ts = time.time()\n",
    "        images, labels = data\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        images = images.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        labels = labels[0]\n",
    "        unary = augment_label(labels, num_classes=num_classes)\n",
    "        unary = unary.transpose(2, 0, 1).reshape([1, num_classes, unary.shape[0], unary.shape[1]])\n",
    "\n",
    "        unary = torch.from_numpy(unary).float().to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(unary=unary, img=images)\n",
    "        \n",
    "        outputs = outputs.transpose(1,2).transpose(2,3).contiguous().view(-1, 21)\n",
    "        labels = labels.view(-1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss_avg.update(loss.item())\n",
    "        time_avg.update(time.time() - start_ts)\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            print('[{:d}, {:d}] Average loss: {:.4f} Average Time: {:.4f} '\n",
    "                  .format(epoch + 1, i, train_loss_avg.avg, time_avg.avg))\n",
    "            \n",
    "            train_loss_avg.reset()\n",
    "            time_avg.reset()\n",
    "            \n",
    "        if i == len(traincrf_loader) - 1:\n",
    "            logger.info('Doing validation at Epoch: {}'.format(epoch + 1))\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_len = len(val_loader)\n",
    "                for i_val, (images_val, labels_val) in enumerate(val_loader):\n",
    "                    labels_val = labels_val[0] # remove batch dimension\n",
    "                    unary = augment_label(labels_val, num_classes=num_classes)\n",
    "                    \n",
    "                    unary = unary.transpose(2, 0, 1).reshape([1, num_classes, unary.shape[0], unary.shape[1]])\n",
    "                    unary = torch.from_numpy(unary).float().to(device)\n",
    "                    \n",
    "                    images_val = images_val.to(device)\n",
    "                    labels_val = labels_val.to(device)\n",
    "                    \n",
    "                    predictions = model(unary=unary, img=images_val)\n",
    "                    pred = predictions.transpose(1,2).transpose(2,3).contiguous().view(-1, 21)\n",
    "                    \n",
    "                    labels = labels_val.view(-1)\n",
    "                    val_loss = criterion(pred, labels)\n",
    "                    \n",
    "                    preds_np = predictions.data.max(1)[1].cpu().numpy()[0]\n",
    "                    labels_np = labels_val.data.cpu().numpy()\n",
    "                    \n",
    "                    running_metrics.update(labels_np, preds_np)\n",
    "                    val_loss_avg.update(val_loss.item())\n",
    "                    \n",
    "                    if i_val > 0 and i_val % 200 == 0:\n",
    "                        print(\"{}/{} Loss: {}: \".format(i_val, val_len))\n",
    "                \n",
    "            logger.info(\"Epoch %d Loss: %.4f\" % (epoch + 1, val_loss_avg.avg))\n",
    "            score, class_iou = running_metrics.get_scores()\n",
    "            \n",
    "            print('\\nEpoch: {} Validation Suammry'.format(epoch + 1))\n",
    "            for k, v in score.items():\n",
    "                print(k, v)\n",
    "            #   writer.add_scalar('val_metrics/{}'.format(k), v, i+1)\n",
    "        \n",
    "            running_metrics.reset()\n",
    "        \n",
    "            if score[\"Mean IoU : \\t\"] >= best_iou:\n",
    "                best_iou = score[\"Mean IoU : \\t\"]\n",
    "                logger.info('Found new best_iou: {}'.format(best_iou))\n",
    "                state = {\n",
    "                        \"epoch\": epoch + 1,\n",
    "                        \"model_state\": model.state_dict(),\n",
    "                        \"optimizer_state\": optimizer.state_dict(),\n",
    "                        \"best_iou\": best_iou,\n",
    "                        }\n",
    "                save_path = os.path.join(\"/home/jupyter/projects/ConvCRF/datasets\",\n",
    "                                         \"best_model.pkl\")\n",
    "                logger.info(save_path)\n",
    "                torch.save(state, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
