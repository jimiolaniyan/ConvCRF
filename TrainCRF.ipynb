{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook contains the code for training the CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-11 11:11:50,046 INFO Device is cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import timeit\n",
    "import warnings\n",
    "import logging as logger\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from convcrf.convcrf import GaussCRF, default_conf\n",
    "from utils.synthetic import augment_label\n",
    "from utils.metrics import Metrics, Averages\n",
    "from demo import do_crf_inference\n",
    "\n",
    "logger.basicConfig(format='%(asctime)s %(levelname)s %(message)s',\n",
    "                    level=logger.INFO,\n",
    "                    stream=sys.stdout)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "logger.info('Device is {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1449"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from utils.pascal_loader import PascalDatasetLoader\n",
    "\n",
    "path = '/home/jimiolaniyan/Documents/Research/DataSets/PASCAL/VOCdevkit/VOC2012'\n",
    "traincrf_dataset = PascalDatasetLoader(path, split='traincrf')\n",
    "val_dataset = PascalDatasetLoader(path, split='val')\n",
    "\n",
    "num_classes = traincrf_dataset.num_classes\n",
    "\n",
    "traincrf_loader = DataLoader(traincrf_dataset, num_workers=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, num_workers=8)\n",
    "len(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = default_conf\n",
    "model = GaussCRF(conf=config, shape=(500, 500), nclasses=num_classes)\n",
    "model.to(device)\n",
    "model.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion= nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "running_metrics = Metrics(num_classes)\n",
    "val_loss_avg = Averages()\n",
    "time_avg = Averages()\n",
    "\n",
    "best_iou = -100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    20] loss: 1.961\n",
      "[1,    40] loss: 1.286\n",
      "[1,    60] loss: 1.256\n",
      "[1,    80] loss: 1.456\n",
      "[1,   100] loss: 1.817\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10): \n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(data_loader):\n",
    "        images, labels = data\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        images = images.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        labels = labels[0]\n",
    "        unary = augment_label(labels, num_classes=num_classes)\n",
    "        unary = unary.transpose(2, 0, 1).reshape([1, num_classes, unary.shape[0], unary.shape[1]])\n",
    "\n",
    "        unary = torch.from_numpy(unary).float().to(device)\n",
    "\n",
    "        outputs = model(unary=unary, img=images)\n",
    "\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = outputs.transpose(1,2).transpose(2,3).contiguous().view(-1, 21)\n",
    "        labels = labels.view(-1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "#             print(\"loss is: {} and running_loss is: {}\".format(loss, running_loss))\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, counter, running_loss / 20))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "        if i == len(data_loader) - 1:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for i_val, (images_val, labels_val) in tqdm(enumerate(val_loader)):\n",
    "                    labels_val = labels_val[0] # remove batch dimension\n",
    "                    unary = augment_label(labels_val, num_classes=num_classes)\n",
    "                    predictions = do_crf_inference(images_val, unary, args)\n",
    "                    \n",
    "                    predictions = predictions.transpose(1,2).transpose(2,3).contiguous().view(-1, 21)\n",
    "                    labels_val = labels.view(-1)\n",
    "                    \n",
    "                    loss = criterion(predictions, labels_val)\n",
    "                    running_metrics_val.update()\n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
