{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional CRFs for Semantic Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook contains code and results of experiments on the ICLR Paper submisson \"Convolutional CRFs for Semantic Segmentation\" as part of the ICLR 2019 Reproducibility challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import skimage.transform\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from convcrf.convcrf import default_conf, test_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS = 'data/img_bicycle_labels.png'\n",
    "labels = imageio.imread(LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce unary by adding noise to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimiolaniyan/anaconda2/envs/mldl/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    }
   ],
   "source": [
    "num_classes = 21\n",
    "keep_prop=0.8\n",
    "scale=8\n",
    "\n",
    "#output\n",
    "unary = None\n",
    "\n",
    "shape = labels.shape # (H, W)\n",
    "labels = labels.reshape(shape[0], shape[1]) # H * W\n",
    "\n",
    "# Onehot encoding of labels\n",
    "onehot = np.eye(num_classes)[labels] # H * W * num_classes\n",
    "\n",
    "\n",
    "lower_shape =  (shape[0] // scale, shape[1] // scale)\n",
    "\n",
    "# Scale down onehot labels to 1/8\n",
    "label_down = skimage.transform.resize(onehot, \n",
    "                                      (lower_shape[0], lower_shape[1], num_classes), \n",
    "                                      order=1, \n",
    "                                      preserve_range=True, \n",
    "                                      mode='constant') # (lower_shape[0], lower_shape[1], num_classes)\n",
    "\n",
    "# scale up onehot of labels to original\n",
    "onehot_up = skimage.transform.resize(label_down,\n",
    "                                      (shape[0], shape[1], num_classes),\n",
    "                                      order=1, preserve_range=True,\n",
    "                                      mode='constant')\n",
    "\n",
    "\n",
    "noise = np.random.randint(0, num_classes, lower_shape)  # Random ints with scaled shape in num_classes range\n",
    "noise = np.eye(num_classes)[noise] # sclaed shape * num_classes\n",
    "\n",
    "# scale up noise labels\n",
    "noise_up = skimage.transform.resize(noise,\n",
    "                                    (shape[0], shape[1], num_classes),\n",
    "                                    order=1, preserve_range=True,\n",
    "                                    mode='constant') \n",
    "\n",
    "mask = np.floor(keep_prop + np.random.rand(*lower_shape))\n",
    "\n",
    "mask_up = skimage.transform.resize(mask, (shape[0], shape[1], 1),\n",
    "                                       order=1, preserve_range=True,\n",
    "                                       mode='constant')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unary = mask_up * onehot_up + (1 - mask_up) * noise_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _get_ind(dz):\n",
    "    if dz == 0:\n",
    "        return 0, 0\n",
    "    if dz < 0:\n",
    "        return 0, -dz\n",
    "    if dz > 0:\n",
    "        return dz, 0\n",
    "\n",
    "\n",
    "def _negative(dz):\n",
    "    \"\"\"\n",
    "    Computes -dz for numpy indexing. Goal is to use as in array[i:-dz].\n",
    "\n",
    "    However, if dz=0 this indexing does not work.\n",
    "    None needs to be used instead.\n",
    "    \"\"\"\n",
    "    if dz == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return -dz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement message passing\n",
    "In the mean field algorithm used in FullCRF (Krähenbühl & Koltun, 2011), the message passing is the bottleneck. Due to the assumption of conditional independence, we can now reformulate message passing as convolutions to get two-orders of magnitude speed up in inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MessagePassingCol():\n",
    "    def __init__(self, feat_list, compat_list, merge, npixels, nlcasses, norm='sym', \n",
    "                 filter_size=5, clip_edges=0, use_gpu=False, blur=1, matmul=False, \n",
    "                 verbose=False, pyinn=False):\n",
    "        \n",
    "        span = filter_size // 2\n",
    "        self.span = span\n",
    "        self.filter_size = filter_size\n",
    "        self.use_gpu = use_gpu\n",
    "        self.verbose = verbose\n",
    "        self.blur = blur\n",
    "        self.pyinn = pyinn\n",
    "        self.merge = merge\n",
    "        self.npixels = npixels\n",
    "        \n",
    "        if not self.blur == 1 and self.blur % 2:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        self.matmul = matmul\n",
    "        self._gaus_list = []\n",
    "        self._norm_list = []\n",
    "        \n",
    "        for feats, compat in zip(feat_list, compat_list):\n",
    "            gaussian = self._create_convolutional_filters()\n",
    "            \n",
    "    def _create_convolutional_filters(self, features):\n",
    "        span = self.span\n",
    "        bs = features.shape[0]\n",
    "        \n",
    "        if self.blur > 1:\n",
    "            off_0 = (self.blur - self.npixels[0] % self.blur) % self.blur\n",
    "            off_1 = (self.blur - self.npixels[1] % self.blur) % self.blur\n",
    "            pad_0 = math.ceil(off_0 / 2)\n",
    "            pad_1 = math.ceil(off_1 / 2)\n",
    "            \n",
    "\n",
    "            features = torch.nn.functional.avg_pool2d(features,\n",
    "                                                      kernel_size=self.blur,\n",
    "                                                      padding=(pad_0, pad_1),\n",
    "                                                      count_include_pad=False)\n",
    "\n",
    "            npixels = [math.ceil(self.npixels[0] / self.blur),\n",
    "                       math.ceil(self.npixels[1] / self.blur)]\n",
    "            \n",
    "            assert(npixels[0] == features.shape[2])\n",
    "            assert(npixels[1] == features.shape[3])\n",
    "        else:\n",
    "            npixels = self.npixels\n",
    "\n",
    "        gaussian_tensor = features.data.new(\n",
    "            bs, self.filter_size, self.filter_size,\n",
    "            npixels[0], npixels[1]).fill_(0)\n",
    "\n",
    "        gaussian = Variable(gaussian_tensor)\n",
    "        \n",
    "        \n",
    "        for dx in range(-span, span + 1):\n",
    "            for dy in range(-span, span + 1):\n",
    "\n",
    "                dx1, dx2 = _get_ind(dx)\n",
    "                dy1, dy2 = _get_ind(dy)\n",
    "\n",
    "                feat_t = features[:, :, dx1:_negative(dx2), dy1:_negative(dy2)]\n",
    "                feat_t2 = features[:, :, dx2:_negative(dx1), dy2:_negative(dy1)] # NOQA\n",
    "\n",
    "                diff = feat_t - feat_t2\n",
    "                diff_sq = diff * diff\n",
    "                exp_diff = torch.exp(torch.sum(-0.5 * diff_sq, dim=1))\n",
    "\n",
    "                gaussian[:, dx + span, dy + span,\n",
    "                         dx2:_negative(dx1), dy2:_negative(dy1)] = exp_diff\n",
    "\n",
    "        return gaussian.view(\n",
    "            bs, 1, self.filter_size, self.filter_size,\n",
    "            npixels[0], npixels[1])\n",
    "\n",
    "mess = MessagePassingCol([], [], [], [], [])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvCRF\n",
    "Full implementation of a generic CRF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConvCRF(nn.Module):\n",
    "    def __init__(self, npixels, nclasses, conf, mode='conv', \n",
    "                 filter_size=5, clip_edges=0, blur=1, use_gpu=False,\n",
    "                 norm='sym', merge=False,verbose=False, trainable=False,\n",
    "                 convcomp=False, weight=None, final_softmax=True,\n",
    "                 unary_weight=10, pyinn=False):\n",
    "        \n",
    "        super(ConvCRF, self).__init__()\n",
    "        \n",
    "        self.nclasses = nclasses\n",
    "        self.filter_size = filter_size\n",
    "        self.clip_edges = clip_edges\n",
    "        self.use_gpu = use_gpu\n",
    "        self.mode = mode\n",
    "        self.norm = norm\n",
    "        self.merge = merge\n",
    "        self.kernel = None\n",
    "        self.verbose = verbose\n",
    "        self.blur = blur\n",
    "        self.final_softmax = final_softmax\n",
    "        self.pyinn = pyinn\n",
    "        self.conf = conf\n",
    "        self.unary_weight = unary_weight\n",
    "        \n",
    "        if type(npixels) is tuple or type(npixels) is list:\n",
    "            self.height = npixels[0]\n",
    "            self.width = npixels[1]\n",
    "        else:\n",
    "            self.npixels = npixels\n",
    "            \n",
    "        if trainable:\n",
    "            def register(name, tensor):\n",
    "                self.register_parameter(name, Parameter(tensor))\n",
    "        else:\n",
    "            def register(name, tensor):\n",
    "                self.register_buffer(name, Variable(tensor))\n",
    "        \n",
    "        if weight is None:\n",
    "            self.weight = None\n",
    "        else:\n",
    "            register('weight', weight)\n",
    "        \n",
    "        if convcomp:\n",
    "            self.comp = nn.Conv2d(nclasses, nclasses, kernel_size=1, padding=0, stride=1, bias=False)\n",
    "            self.comp.weight.data.fill_(0.1 * math.sqrt(2.0 / nclasses))\n",
    "        else:\n",
    "            self.comp = None\n",
    "\n",
    "    def clean_filters(self):\n",
    "        self.kernel = None\n",
    "\n",
    "    def add_pairwise_energies(self, feat_list, compat_list, merge):\n",
    "        assert(len(feat_list) == len(compat_list))\n",
    "\n",
    "        assert(self.use_gpu)\n",
    "\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussCRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GaussCRF(nn.Module):\n",
    "    def __init__(self, conf, shape, nclasses=None):\n",
    "        super(GaussCRF, self).init()\n",
    "        self.conf = confb\n",
    "        self.shape = shape\n",
    "        self.nclasses = nclasses\n",
    "        \n",
    "        self.trainable = conf['trainable']\n",
    "        \n",
    "        if not conf['trainable_bias']:\n",
    "            self.register_buffer('mesh', self._create_mesh())\n",
    "        else:\n",
    "            self.register_parameter('mesh', Parameter(self._create_mesh()))\n",
    "        \n",
    "        if self.trainable:\n",
    "            def register(name, tensor):\n",
    "                self.register_parameter(name, Parameter(tensor))\n",
    "        else:\n",
    "            def register(name, tensor):\n",
    "                self.register_buffer(name, Variable(tensor))\n",
    "        \n",
    "        register('pos_sdims', torch.Tensor([1 / conf['pos_feats']['sdims']]))\n",
    "        \n",
    "        if conf['col_feats']['use_bias']:\n",
    "            register('col_sdims', torch.Tensor([1 / conf['col_feats']['sdims']]))\n",
    "        else:\n",
    "            self.col_sdims = None\n",
    "\n",
    "        register('col_schan', torch.Tensor([1 / conf['col_feats']['schan']]))\n",
    "        register('col_compat', torch.Tensor([conf['col_feats']['compat']]))\n",
    "        register('pos_compat', torch.Tensor([conf['pos_feats']['compat']]))\n",
    "            \n",
    "        if conf['weight'] is None:\n",
    "            weight = None\n",
    "        elif conf['weight'] == 'scalar':\n",
    "            val = conf['weight_init']\n",
    "            weight = torch.Tensor([val])\n",
    "        elif conf['weight'] == 'vector':\n",
    "            val = conf['weight_init']\n",
    "            weight = val * torch.ones(1, nclasses, 1, 1)\n",
    "\n",
    "    def _create_mesh(self, requires_grad=False):\n",
    "        hcord_range = [range(s) for s in self.shape]\n",
    "        mesh = np.array(np.meshgrid(*hcord_range, indexing='ij'),\n",
    "                        dtype=np.float32)\n",
    "        return torch.from_numpy(mesh)\n",
    "    \n",
    "    def forward(self, unary, img, num_iter=5):\n",
    "        conf = self.conf\n",
    "        bs, c, x, y = img.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 21, 500, 334)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG = 'data/img_bicycle.png'\n",
    "image = imageio.imread(IMG)\n",
    "\n",
    "FILTER_SIZE = 7\n",
    "\n",
    "shape = image.shape[0:2]\n",
    "config = default_conf\n",
    "config['filter_size'] = FILTER_SIZE\n",
    "\n",
    "\n",
    "# Pytorch uses C, H, W\n",
    "# image = image.transpose(2,0,1) # [C, H, W]\n",
    "image = image.transpose(2, 0, 1)  # shape: [3, hight, width]\n",
    "\n",
    "# Add bactch dim\n",
    "image = image.reshape([1, 3, shape[0], shape[1]]) \n",
    "# img_var = Variable(torch.Tensor(image)).cuda()\n",
    "\n",
    "unary = unary.transpose(2, 0, 1)  # shape: [3, hight, width]\n",
    "# Add batch dim\n",
    "unary = unary.reshape([1, num_classes, shape[0], shape[1]])\n",
    "\n",
    "# unary_var = Variable(torch.Tensor(unary)).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dotmap import DotMap\n",
    "\n",
    "args = DotMap()\n",
    "args.pyinn = False\n",
    "args.nospeed = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction = do_crf_inference(image, unary, args)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mldl]",
   "language": "python",
   "name": "conda-env-mldl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
